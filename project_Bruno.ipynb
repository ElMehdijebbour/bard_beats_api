{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering by user\n",
    "\n",
    "User --> Songs ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs for User 969cc6fb74e076a68e36a04409cb9d3765757508 :\n",
      "['SOERLVY12AB01842AA', 'SOFXVLQ12AF72AD42E', 'SOALKBV12A6D4F6EE2', 'SODHPUM12AF72A1DF2', 'SORWULZ12A6D4F5B1E', 'SOPTLQL12AB018D56F', 'SOINKUL12AB0188B02', 'SOETLEX12AF72A3070', 'SOSDIVF12A8C13F067', 'SORUYEG12B0B807430']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'song_dataset.csv'  # Update the file path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "## Remove duplicates if any\n",
    "data = data.drop_duplicates(['user', 'song'])\n",
    "\n",
    "## Create a pivot table with users as rows and songs as columns\n",
    "pivot_table = data.pivot(index='user', columns='song', values='play_count').fillna(0)\n",
    "\n",
    "## Convert the pivot table to a sparse matrix\n",
    "matrix = csr_matrix(pivot_table.values)\n",
    " \n",
    "# Building the Model - Using K-Nearest Neighbors\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "model_knn.fit(matrix)\n",
    "\n",
    "# Function to recommend songs for a user\n",
    "def recommend_songs_for_user(model, pivot_table, user_id, n_recommendations):\n",
    "    if user_id not in pivot_table.index:\n",
    "        return \"User ID not found in the dataset.\"\n",
    "\n",
    "    user_idx = pivot_table.index.get_loc(user_id)\n",
    "    distances, indices = model.kneighbors(pivot_table.iloc[user_idx, :].values.reshape(1, -1), n_neighbors=20)\n",
    "    \n",
    "    # Get the songs listened to by the user\n",
    "    listened_songs = set(pivot_table.columns[pivot_table.iloc[user_idx].to_numpy().nonzero()[0]].tolist())\n",
    "\n",
    "    recommend_list = set()\n",
    "    for idx in indices.flatten():\n",
    "        if idx == user_idx:\n",
    "            continue  # skip the user itself\n",
    "        # Add songs listened by similar users, excluding those already listened by the user\n",
    "        user_songs = set(pivot_table.columns[pivot_table.iloc[idx].to_numpy().nonzero()[0]].tolist())\n",
    "        recommend_list.update(user_songs)\n",
    "\n",
    "    # Remove already listened songs and limit the number of recommendations\n",
    "    recommend_list.difference_update(listened_songs)\n",
    "    recommend_list = list(recommend_list)[:n_recommendations]\n",
    "\n",
    "    return recommend_list\n",
    "\n",
    "# Example Usage\n",
    "user_id = '969cc6fb74e076a68e36a04409cb9d3765757508'\n",
    "recommendations = recommend_songs_for_user(model_knn, pivot_table, user_id, 10)\n",
    "print(\"Recommended Songs for User\", user_id, \":\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Names:\n",
      "Billionaire [feat. Bruno Mars]  (Explicit Album Version)\n",
      "Queen Of My Double Wide Trailer\n",
      "Blind\n",
      "Bumpy's Lament\n",
      "So Beautiful\n",
      "Get Up\n",
      "You Will Always Be The Same\n",
      "Becoming Insane\n",
      "Missy\n",
      "Be My Baby\n"
     ]
    }
   ],
   "source": [
    "# List of song IDs for which you want to find the song names\n",
    "song_ids = recommendations\n",
    "\n",
    "# Filter the dataset for the given song IDs and retrieve their names\n",
    "song_names = data[data['song'].isin(song_ids)]['title'].drop_duplicates().tolist()\n",
    "\n",
    "# Print the song names\n",
    "print(\"Song Names:\")\n",
    "for name in song_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By list of songs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list = ['SOBFNSP12AF72A0E22', 'SOIAOBY12A8C13BF75','SORJMZL12A8C13AC49']\n",
    "\n",
    "user_song_ids = ['SOBFNSP12AF72A0E22', 'SOIAOBY12A8C13BF75', 'SORJMZL12A8C13AC49']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering\n",
    "\n",
    "Songs ID list --> Recommended songs ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs: ['SOAXGDH12A8C13F8A1', 'SODJWHY12A8C142CCE', 'SOFRQTD12A81C233C0', 'SOLFXKT12AB017E3E0', 'SONYKOW12AB01849C9', 'SOTWNDJ12A8C143984', 'SOUSMXX12AB0185C24', 'SOUVTSM12AC468F6A7', 'SOWCKVR12A8C142411', 'SOAUWYT12A81C206F1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('song_dataset.csv')  # Update with the path to your dataset\n",
    "\n",
    "# Preprocessing\n",
    "## Remove duplicates if any\n",
    "data = data.drop_duplicates(['user', 'song'])\n",
    "\n",
    "## Aggregate play counts for each user-song pair\n",
    "data_agg = data.groupby(['user', 'song']).play_count.sum().reset_index()\n",
    "\n",
    "## Create a pivot table\n",
    "pivot_table = data_agg.pivot(index='user', columns='song', values='play_count').fillna(0)\n",
    "\n",
    "## Create a sparse matrix\n",
    "matrix = csr_matrix(pivot_table.values)\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "cosine_sim = cosine_similarity(matrix)\n",
    "\n",
    "# Function to Recommend Songs\n",
    "def recommend_songs_collaborative_filtering(input_songs, pivot_table, cosine_sim, top_n=10):\n",
    "    # Create a pseudo-user vector\n",
    "    pseudo_user = pd.Series(0, index=pivot_table.columns)\n",
    "    for song in input_songs:\n",
    "        if song in pseudo_user.index:\n",
    "            pseudo_user[song] = 1\n",
    "\n",
    "    # Find similar users\n",
    "    pseudo_user_matrix = csr_matrix(pseudo_user.values.reshape(1, -1))\n",
    "    sim_scores = cosine_similarity(pseudo_user_matrix, matrix).flatten()\n",
    "    similar_users = sim_scores.argsort()[::-1][1:]  # Excluding the pseudo-user itself\n",
    "\n",
    "    # Aggregate recommendations from similar users\n",
    "    song_recs = {}\n",
    "    for user_idx in similar_users[:20]:  # Consider top 20 similar users\n",
    "        user_songs = pivot_table.columns[(pivot_table.iloc[user_idx] > 0)].tolist()\n",
    "        for song in user_songs:\n",
    "            if song not in input_songs:\n",
    "                song_recs[song] = song_recs.get(song, 0) + sim_scores[user_idx]\n",
    "\n",
    "    recommended_songs = sorted(song_recs, key=song_recs.get, reverse=True)[:top_n]\n",
    "    return recommended_songs\n",
    "\n",
    "# Example Usage\n",
    "input_songs = user_song_ids\n",
    "recommended_song_ids_cf = recommend_songs_collaborative_filtering(input_songs, pivot_table, cosine_sim)\n",
    "print(\"Recommended Songs:\", recommended_song_ids_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Names:\n",
      "Sehr kosmisch\n",
      "Undo\n",
      "Dog Days Are Over (Radio Edit)\n",
      "Hey_ Soul Sister\n",
      "Fireflies\n",
      "Secrets\n",
      "Marry Me\n",
      "OMG\n",
      "Drop The World\n",
      "Use Somebody\n"
     ]
    }
   ],
   "source": [
    "# List of song IDs for which you want to find the song names\n",
    "song_ids = recommended_song_ids_cf\n",
    "\n",
    "# Filter the dataset for the given song IDs and retrieve their names\n",
    "song_names = data[data['song'].isin(song_ids)]['title'].drop_duplicates().tolist()\n",
    "\n",
    "# Print the song names\n",
    "print(\"Song Names:\")\n",
    "for name in song_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Filtering\n",
    "\n",
    "Songs ID list --> Recommended songs ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs: ['SOJXJHW12A6D4F8AE5', 'SOBVFZR12A6D4F8AE3', 'SOBVFZR12A6D4F8AE3', 'SOEOBYG12A6D4F8AE2', 'SOEOBYG12A6D4F8AE2', 'SOEGVZY12A58A7857E', 'SORJNVW12A8C13BF90']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('song_dataset.csv')  # Update with the path to your dataset\n",
    "\n",
    "# Data Preprocessing\n",
    "## Combine text features for content-based filtering\n",
    "data['combined_features'] = data['title'] + ' ' + data['artist_name'] + ' ' + data['release']\n",
    "\n",
    "# Content-based Features using TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "def recommend_songs_content_based(input_songs, data, tfidf_matrix, top_n=10):\n",
    "    song_indices = [data.index[data['song'] == song_id].tolist()[0] for song_id in input_songs if song_id in data['song'].values]\n",
    "    \n",
    "    # Aggregate the similarities of input songs with all songs\n",
    "    aggregate_sim_scores = sum(cosine_similarity(tfidf_matrix[song_idx], tfidf_matrix) for song_idx in song_indices)\n",
    "\n",
    "    # Flatten the similarity scores array and get top N indices\n",
    "    sim_scores_flattened = aggregate_sim_scores.flatten()\n",
    "    recommended_song_indices = sim_scores_flattened.argsort()[-top_n-len(input_songs):-len(input_songs)][::-1]\n",
    "    \n",
    "    # Get recommended song IDs excluding the input songs\n",
    "    recommended_song_ids = [data.iloc[idx]['song'] for idx in recommended_song_indices if data.iloc[idx]['song'] not in input_songs]\n",
    "\n",
    "    return recommended_song_ids\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "input_songs = user_song_ids\n",
    "recommended_song_ids_cb = recommend_songs_content_based(input_songs, data, tfidf_matrix)\n",
    "print(\"Recommended Songs:\", recommended_song_ids_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Names:\n",
      "Ears To The Ground (Album Version)\n",
      "Nothing Gives Me Pleasure\n",
      "Ugly Stories\n",
      "Wonderful (Album Version)\n",
      "Women And Men (Album Version)\n"
     ]
    }
   ],
   "source": [
    "# List of song IDs for which you want to find the song names\n",
    "song_ids = recommended_song_ids_cb\n",
    "\n",
    "# Filter the dataset for the given song IDs and retrieve their names\n",
    "song_names = data[data['song'].isin(song_ids)]['title'].drop_duplicates().tolist()\n",
    "\n",
    "# Print the song names\n",
    "print(\"Song Names:\")\n",
    "for name in song_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid approach\n",
    "\n",
    "Songs ID list --> Recommended songs ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs: ['SOBVFZR12A6D4F8AE3', 'SOEGVZY12A58A7857E', 'SOEOBYG12A6D4F8AE2', 'SOIQOQT12A8C136F96', 'SOOSIVQ12A6D4F8AE0', 'SOUSMXX12AB0185C24', 'SOGIYND12AB017B10E', 'SOCKYCG12A58A78E37', 'SOBNXJY12A8C13E070', 'SOXTMZY12AB01866D5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('song_dataset.csv')  # Update with your dataset's file path\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "## Remove duplicates if any\n",
    "data = data.drop_duplicates(['user', 'song'])\n",
    "\n",
    "## Combine text features for content-based filtering\n",
    "data['combined_features'] = data['title'] + ' ' + data['artist_name'] + ' ' + data['release']\n",
    "\n",
    "# Content-based Features\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "# Data Preprocessing for Collaborative Filtering\n",
    "## Aggregate play counts for each user-song pair\n",
    "agg_data = data.groupby(['user', 'song']).agg({'play_count': 'sum'}).reset_index()\n",
    "\n",
    "## Create pivot table\n",
    "pivot_table = agg_data.pivot(index='user', columns='song', values='play_count').fillna(0)\n",
    "matrix = csr_matrix(pivot_table.values)\n",
    "svd = TruncatedSVD(n_components=20)  # Reduced number of components\n",
    "latent_matrix = svd.fit_transform(matrix)\n",
    "\n",
    "def recommend_songs_hybrid(user_songs, all_songs, tfidf_matrix, latent_matrix, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommends songs based on a hybrid approach combining content-based and collaborative filtering.\n",
    "    \n",
    "    Args:\n",
    "    user_songs: List of song IDs the user has already listened to.\n",
    "    all_songs: DataFrame of all songs.\n",
    "    tfidf_matrix: TF-IDF matrix for content-based features.\n",
    "    latent_matrix: Matrix from SVD for collaborative features.\n",
    "    top_n: Number of top recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame of recommended songs.\n",
    "    \"\"\"\n",
    "    # Filter out user songs that are not in the dataset\n",
    "    valid_user_songs = [song for song in user_songs if song in all_songs['song'].values]\n",
    "\n",
    "    # Get indices for valid user songs in the TF-IDF matrix\n",
    "    valid_song_indices = [all_songs[all_songs['song'] == song].index[0] for song in valid_user_songs]\n",
    "    \n",
    "    # Content-based recommendations\n",
    "    song_matrix = vstack([tfidf_matrix[i] for i in valid_song_indices])\n",
    "    cosine_sim = cosine_similarity(song_matrix, tfidf_matrix)\n",
    "    sim_scores = cosine_sim.mean(axis=0)\n",
    "    content_based_recommendations = [all_songs['song'].iloc[i] for i in sim_scores.argsort()[-top_n:][::-1]]\n",
    "\n",
    "    # Collaborative filtering recommendations\n",
    "    user_vector = latent_matrix.mean(axis=0).reshape(1, -1)\n",
    "    cosine_sim = cosine_similarity(user_vector, latent_matrix)\n",
    "    sim_scores = cosine_sim[0]\n",
    "    collaborative_recommendations = [all_songs['song'].iloc[i] for i in sim_scores.argsort()[-top_n:][::-1]]\n",
    "\n",
    "    # Combine and filter out songs the user has already listened to\n",
    "    combined_recommendations = list(set(content_based_recommendations + collaborative_recommendations))\n",
    "    combined_recommendations = [song for song in combined_recommendations if song not in valid_user_songs]\n",
    "\n",
    "    return all_songs[all_songs['song'].isin(combined_recommendations)].drop_duplicates('song').head(top_n)\n",
    "\n",
    "# Example Usage\n",
    "recommended_songs_hybrid = recommend_songs_hybrid(user_song_ids, data, tfidf_matrix, latent_matrix)\n",
    "print(\"Recommended Songs:\", recommended_songs_hybrid['song'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Names:\n",
      "Ears To The Ground (Album Version)\n",
      "Nothing Gives Me Pleasure\n",
      "Ugly Stories\n",
      "Pilgrim\n",
      "Christmas With Jesus (Album Version)\n",
      "OMG\n",
      "Live-In Skin\n",
      "Hippie Priest Bum-out (Edit)\n",
      "The Execution Of All Things (Single Version)\n",
      "Underdog (In The Style of 'You Me At Six') [No Backing Vocals]\n"
     ]
    }
   ],
   "source": [
    "# List of song IDs for which you want to find the song names\n",
    "song_ids = recommended_songs_hybrid['song'].tolist()\n",
    "\n",
    "# Filter the dataset for the given song IDs and retrieve their names\n",
    "song_names = data[data['song'].isin(song_ids)]['title'].drop_duplicates().tolist()\n",
    "\n",
    "# Print the song names\n",
    "print(\"Song Names:\")\n",
    "for name in song_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarities in the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collaborative vs hybrid :\n",
      "Overlap Ratio : 0.1\n",
      "Jaccard Similarity : 0.05263157894736842\n",
      "Content-Based vs hybrid :\n",
      "Overlap Ratio : 0.42857142857142855\n",
      "Jaccard Similarity : 0.25\n"
     ]
    }
   ],
   "source": [
    "def calculate_overlap_ratio(list1, list2):\n",
    "    \"\"\"Calculate the overlap ratio between two lists.\"\"\"\n",
    "    common_elements = set(list1).intersection(set(list2))\n",
    "    return len(common_elements) / min(len(list1), len(list2))\n",
    "\n",
    "def calculate_jaccard_similarity(list1, list2):\n",
    "    \"\"\"Calculate Jaccard similarity between two lists.\"\"\"\n",
    "    intersection = set(list1).intersection(set(list2))\n",
    "    union = set(list1).union(set(list2))\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "recs_collaborative = recommended_song_ids_cf # recommendations from collaborative method\n",
    "recs_cb = recommended_song_ids_cb # recommendations from Content-Based method\n",
    "recs_hybrid = recommended_songs_hybrid['song'].tolist()   # recommendations from hybrid method\n",
    "\n",
    "# Calculate similarities\n",
    "overlap_ratio = calculate_overlap_ratio(recs_hybrid, recs_collaborative)\n",
    "jaccard_similarity = calculate_jaccard_similarity(recs_hybrid, recs_collaborative)\n",
    "print(f\"collaborative vs hybrid :\")\n",
    "print(f\"Overlap Ratio : {overlap_ratio}\")\n",
    "print(f\"Jaccard Similarity : {jaccard_similarity}\")\n",
    "\n",
    "# Calculate similarities\n",
    "overlap_ratio = calculate_overlap_ratio(recs_hybrid, recs_cb)\n",
    "jaccard_similarity = calculate_jaccard_similarity(recs_hybrid, recs_cb)\n",
    "print(f\"Content-Based vs hybrid :\")\n",
    "print(f\"Overlap Ratio : {overlap_ratio}\")\n",
    "print(f\"Jaccard Similarity : {jaccard_similarity}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
